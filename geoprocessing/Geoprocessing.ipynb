{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geoprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Geoprocessing\" data-toc-modified-id=\"Geoprocessing-1\">Geoprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\">Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-geoprocessing?\" data-toc-modified-id=\"What-is-geoprocessing?-1.1.1\">What is geoprocessing?</a></span></li><li><span><a href=\"#Geoprocessing-Library-Selection\" data-toc-modified-id=\"Geoprocessing-Library-Selection-1.1.2\">Geoprocessing Library Selection</a></span></li></ul></li><li><span><a href=\"#Geoprocessing-Functions\" data-toc-modified-id=\"Geoprocessing-Functions-1.2\">Geoprocessing Functions</a></span></li><li><span><a href=\"#Geoprocessing-Input-Data\" data-toc-modified-id=\"Geoprocessing-Input-Data-1.3\">Geoprocessing Input Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preparation-and-Cleaning\" data-toc-modified-id=\"Data-Preparation-and-Cleaning-1.3.1\">Data Preparation and Cleaning</a></span></li></ul></li><li><span><a href=\"#Geoprocessing-Methods\" data-toc-modified-id=\"Geoprocessing-Methods-1.4\">Geoprocessing Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distance-Metrics\" data-toc-modified-id=\"Distance-Metrics-1.4.1\">Distance Metrics</a></span></li><li><span><a href=\"#Kernel-Density\" data-toc-modified-id=\"Kernel-Density-1.4.2\">Kernel Density</a></span></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-1.5\">Results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### What is geoprocessing?\n",
    "\n",
    "Very broadly, **Geoprocessing** is any operation involving geospatial data. The Geographic Information Systems (GIS) software company Esri refers to it as \"[Computing with geographic data.](http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Comparing_Geoprocessing_and_Spatial_Analysis)\" It is commonly misused interchangeably with the term [Spatial Analysis](http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Comparing_Geoprocessing_and_Spatial_Analysi). However, Spatial Analysis includes the interpretation of the results of Geoprocessing. Spatial Analysis has more in common with the **[Data Science Process](https://medium.springboard.com/the-data-science-process-the-complete-laymans-guide-to-what-a-data-scientist-actually-does-ca3e166b7c67)**, while Geoprocessing has more in common joining, grouping and aggregating data steps in a typical data science project workflow. \n",
    "\n",
    "Professor Jochen Albrecht defines Geoprocessing as;\n",
    "> _...any GIS operation used to manipulate data. A typical geoprocessing operation takes an input dataset, performs an operation on that dataset, and returns the result of the operation as an output dataset, also referred to as derived data. Common geoprocessing operations are geographic feature overlay, feature selection and analysis, topology processing, and data conversion. Geoprocessing allows you to define, manage, and analyze geographic information used to make decisions._ [Jochen Albrecht](http://www.geography.hunter.cuny.edu/~jochen/GTECH361/lectures/lecture12/concepts/01%20What%20is%20geoprocessing.htm)\n",
    "\n",
    "### Geoprocessing Library Selection\n",
    "\n",
    "There are several Geoprocessing libraries and technologies. A few notable open source ones are;\n",
    "\n",
    "* [PostGIS](https://postgis.net/) - Spatially Enabled PostgreSQL \n",
    "* [GeoPandas](https://geopandas.org/) - Pandas Extended with [Shapely](https://shapely.readthedocs.io/en/latest/)\n",
    "* [Arcpy](https://pro.arcgis.com/en/pro-app/arcpy/get-started/what-is-arcpy-.htm) - Esri's Python site package\n",
    "* [PyQGIS](https://docs.qgis.org/testing/en/docs/pyqgis_developer_cookbook/) - [QGIS](https://www.qgis.org/en/site/)'s Python Package\n",
    "\n",
    "\n",
    "Arcpy has more \"out-of-the-box\" functions that could be easily strung together than other python libraries. Of the **[Good-Fast-Cheap](https://medium.com/@devsociety_/good-cheap-fast-pick-two-and-how-ngos-can-play-the-triangle-like-a-pro-20d1380884a8)** paradigm, selecting Arcpy optimizes on the **Fast** component. \n",
    "\n",
    "> ArcPy is a Python site package that provides a useful and productive way to perform geographic data analysis, data conversion, data management, and map automation with Python. [Esri](https://pro.arcgis.com/en/pro-app/arcpy/get-started/what-is-arcpy-.htm)\n",
    "\n",
    "Arcpy is available in both free trial versions as well as paid home and commercial licenses on Windows or virtual Windows operating systems. The [ArcGIS API for Python](https://www.esri.com/en-us/arcgis/trial), using ArcGIS Online is also available for multiple platforms. However, for **fast** Geoprocessing, Arcpy made the most sense. Especially when, in our group team Delta, team members were waiting for the output of the Geoprocessing steps. Rather than be a bottleneck extending GeoPandas or setting up (and also extending) PostGIS, Arcpy helped enable a quicker turnaround of Geoprocessing output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoprocessing Functions\n",
    "\n",
    "In order to leverage Arcpy, simplify the project code, and make it easier to replace Arcpy with another Geoprocessing library, I have wrote wrapper functions for geoprocessing. All of this code is below. One may see the character combination of `fc` quite a bit, quite simply that refers to \"Feature Class\". Read more one what a [Feature Class](https://desktop.arcgis.com/en/arcmap/10.3/manage-data/geodatabases/feature-class-basics.htm) is. Additionally, any `arcpy` functions and methods can be read about in [ArcGIS Pro Python reference](https://pro.arcgis.com/en/pro-app/arcpy/main/arcgis-pro-arcpy-reference.htm). This code is also found in the file `geoprocessing.py` in this repository or in the [Delta repo on GitHub](https://git.generalassemb.ly/delta/delta/blob/master/geoprocessing/geoprocessing.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy  # note, for cell to run, arcpy required. \n",
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputMFlag = \"Disabled\"\n",
    "\n",
    "\n",
    "def calculate_area(in_fc, area_field_name, area_units):\n",
    "    arcpy.AddField_management(\n",
    "        in_table=in_fc,\n",
    "        field_name=area_field_name,\n",
    "        field_type=\"DOUBLE\"\n",
    "    )\n",
    "\n",
    "    arcpy.CalculateField_management(\n",
    "        in_table=in_fc,\n",
    "        field=area_field_name,\n",
    "        expression=\"!shape.area@{}!\".format(area_units),\n",
    "        expression_type=\"PYTHON\",\n",
    "        code_block=\"\",\n",
    "    )  # refactor this to be subset of add_field_calculate\n",
    "\n",
    "\n",
    "def fc_to_fc(input_fc, output_location, output_filename, expression=None):\n",
    "    if expression:\n",
    "        arcpy.FeatureClassToFeatureClass_conversion(\n",
    "            input_fc,\n",
    "            output_location,\n",
    "            output_filename,\n",
    "            expression,\n",
    "        )\n",
    "    else:\n",
    "        arcpy.FeatureClassToFeatureClass_conversion(\n",
    "            input_fc,\n",
    "            output_location,\n",
    "            output_filename,\n",
    "        )\n",
    "\n",
    "\n",
    "def feature_class_to_dataframe(in_fc):\n",
    "    field_list = get_fc_fields(in_fc)\n",
    "    df = pd.DataFrame([row for row in arcpy.da.SearchCursor(in_fc, field_list)])\n",
    "    if len(df.index) > 0:\n",
    "        df.columns = field_list\n",
    "        return df\n",
    "    else:\n",
    "        print(\"            empty dataframe\")\n",
    "        return pd.DataFrame()\n",
    "    # check out https://joelmccune.com/arcgis-to-pandas-data-frame-v2-0/\n",
    "\n",
    "\n",
    "def get_fc_fields(fc):\n",
    "    field_names = []\n",
    "    fields = arcpy.ListFields(fc)\n",
    "    for field in fields:\n",
    "        field_names.append(field.name)\n",
    "    return field_names\n",
    "\n",
    "\n",
    "def intersect(in_fc_1, in_fc_2, output_fc, attributes=\"ALL\"):\n",
    "    arcpy.Intersect_analysis(\n",
    "        \"{} #;{} #\".format(in_fc_1, in_fc_2),\n",
    "        out_feature_class=output_fc,\n",
    "        join_attributes=attributes,\n",
    "        cluster_tolerance=\"-1 Unknown\",\n",
    "        output_type=\"INPUT\",\n",
    "    )\n",
    "\n",
    "\n",
    "def dissolve_on_fields(input_fc, output_fc, dissolve_fields):\n",
    "    arcpy.Dissolve_management(input_fc, output_fc, dissolve_fields)\n",
    "\n",
    "\n",
    "def point_table_to_feature_class(\n",
    "        input_table,\n",
    "        input_x_column,\n",
    "        input_y_column,\n",
    "        spatial_reference_info,\n",
    "        output_location,\n",
    "        output_layer_name,\n",
    "):\n",
    "    uid = generate_uuid()\n",
    "\n",
    "    arcpy.MakeXYEventLayer_management(\n",
    "        table=input_table,\n",
    "        in_x_field=input_x_column,\n",
    "        in_y_field=input_y_column,\n",
    "        out_layer=\"in_memory_layer_{}\".format(uid),\n",
    "        spatial_reference=spatial_reference_info,\n",
    "        in_z_field=\"\",\n",
    "    )\n",
    "\n",
    "    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "        in_features=\"in_memory_layer_{}\".format(uid),\n",
    "        out_path=output_location,\n",
    "        out_name=output_layer_name,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_uuid():\n",
    "    return uuid.uuid4().hex\n",
    "\n",
    "\n",
    "def delete_fields(input_table, list_drop_fields):\n",
    "    arcpy.DeleteField_management(\n",
    "        in_table=input_table,\n",
    "        drop_field=';'.join(list_drop_fields),\n",
    "    )\n",
    "\n",
    "\n",
    "def near_table(in_features, near_features, out_table):\n",
    "    arcpy.GenerateNearTable_analysis(\n",
    "        in_features,\n",
    "        near_features,\n",
    "        out_table,\n",
    "        angle='ANGLE',\n",
    "        method='GEODESIC',\n",
    "        search_radius='10000 kilometers'\n",
    "    )\n",
    "\n",
    "\n",
    "def split_by_attributes(input_fc, workspace, split_fields):\n",
    "    arcpy.SplitByAttributes_analysis(\n",
    "        Input_Table=input_fc,\n",
    "        Target_Workspace=workspace,\n",
    "        Split_Fields=split_fields,\n",
    "    )\n",
    "\n",
    "\n",
    "def add_field_calculate(\n",
    "        in_fc,\n",
    "        new_field_name,\n",
    "        new_field_type,\n",
    "        expression,\n",
    "):\n",
    "    arcpy.AddField_management(\n",
    "        in_table=in_fc,\n",
    "        field_name=new_field_name,\n",
    "        field_type=new_field_type,\n",
    "    )\n",
    "\n",
    "    arcpy.CalculateField_management(\n",
    "        in_table=in_fc,\n",
    "        field=new_field_name,\n",
    "        expression=expression,\n",
    "        expression_type=\"PYTHON\",\n",
    "        code_block=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def select_features_by_query(\n",
    "        input_table,\n",
    "        output_table,\n",
    "        query,\n",
    "):\n",
    "    arcpy.Select_analysis(\n",
    "        in_features=input_table,\n",
    "        out_feature_class=output_table,\n",
    "        where_clause=query,\n",
    "    )\n",
    "\n",
    "\n",
    "def select_overlapping_data(\n",
    "        select_feature,\n",
    "        select_from_dataset,\n",
    "        output_location,\n",
    "        output_layer_name,\n",
    "        message=True,\n",
    "):\n",
    "    uid = generate_uuid()\n",
    "\n",
    "    arcpy.MakeFeatureLayer_management(\n",
    "        select_from_dataset,\n",
    "        'select_from_dataset_{}'.format(uid),\n",
    "    )\n",
    "\n",
    "    arcpy.SelectLayerByLocation_management(\n",
    "        'select_from_dataset_{}'.format(uid),\n",
    "        \"INTERSECT\",\n",
    "        select_feature,\n",
    "        search_distance=\"\",\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        invert_spatial_relationship=\"NOT_INVERT\",\n",
    "    )\n",
    "\n",
    "    arcpy.FeatureClassToFeatureClass_conversion(\n",
    "        'select_from_dataset_{}'.format(uid),\n",
    "        output_location,\n",
    "        output_layer_name\n",
    "    )\n",
    "\n",
    "    arcpy.Delete_management('select_from_dataset_{}'.format(uid))\n",
    "\n",
    "    if message:\n",
    "        print('    selection complete for {}'.format(select_from_dataset))\n",
    "\n",
    "\n",
    "def study_area_circle(in_fc, out_fc):\n",
    "    arcpy.MinimumBoundingGeometry_management(\n",
    "        in_features=in_fc,\n",
    "        out_feature_class=out_fc,\n",
    "        geometry_type=\"CIRCLE\",\n",
    "        group_option=\"ALL\",\n",
    "        group_field=\"\",\n",
    "        mbg_fields_option=\"NO_MBG_FIELDS\",\n",
    "    )\n",
    "\n",
    "\n",
    "def read_json(json_file):\n",
    "    with open(json_file) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def clip_raster(\n",
    "        input_raster,\n",
    "        input_clip_geography,\n",
    "        output_raster,\n",
    "):\n",
    "    arcpy.Clip_management(\n",
    "        in_raster=input_raster,\n",
    "        out_raster=output_raster,\n",
    "        in_template_dataset=input_clip_geography,\n",
    "        clipping_geometry=\"NONE\",\n",
    "        maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\",\n",
    "    )\n",
    "\n",
    "\n",
    "def raster_to_integer(input_raster, output_raster):\n",
    "    arcpy.gp.RasterCalculator_sa(\n",
    "        f'Int(\"{input_raster}\")',\n",
    "        output_raster,\n",
    "    )\n",
    "\n",
    "\n",
    "def raster_to_polygon(input_raster, output_polygon_fc):\n",
    "    arcpy.RasterToPolygon_conversion(\n",
    "        in_raster=input_raster,\n",
    "        out_polygon_features=output_polygon_fc,\n",
    "        simplify=\"NO_SIMPLIFY\",\n",
    "        raster_field=\"Value\",\n",
    "        create_multipart_features=\"SINGLE_OUTER_PART\",\n",
    "        max_vertices_per_feature=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def raster_to_point(input_raster, output_point_fc):\n",
    "    arcpy.RasterToPoint_conversion(\n",
    "        in_raster=input_raster,\n",
    "        out_point_features=output_point_fc,\n",
    "        raster_field=\"Value\",\n",
    "    )\n",
    "\n",
    "\n",
    "def project_data(\n",
    "        input_fc,\n",
    "        output_fc,\n",
    "        out_coordinate_system,\n",
    "):\n",
    "    arcpy.Project_management(\n",
    "        in_dataset=input_fc,\n",
    "        out_dataset=output_fc,\n",
    "        out_coor_system=out_coordinate_system,\n",
    "    )\n",
    "\n",
    "\n",
    "def kernel_density(\n",
    "        input_fc,\n",
    "        output_raster,\n",
    "        cell_size,\n",
    "        search_radius,\n",
    "        population_field=\"NONE\",\n",
    "        area_units=\"SQUARE_KILOMETERS\",\n",
    "):\n",
    "    arcpy.gp.KernelDensity_sa(\n",
    "        input_fc,\n",
    "        population_field,\n",
    "        output_raster,\n",
    "        cell_size,\n",
    "        search_radius,\n",
    "        area_units,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoprocessing Input Data\n",
    "\n",
    "Below is a list of data used in the G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"rj\": {\n",
    "        \"favela_orig\": \"input/favelas/rio_de_janeiro/Limite_Favelas/Limite_Favelas.shp\",\n",
    "        \"favela\": \"input/favelas/rio_de_janeiro/Limite_Favelas/limite_favelas_clean.shp\",\n",
    "        \"census_tract\": \"input/census_tracts/rj_setores_censitarios/33SEE250GC_SIR.shp\",\n",
    "    },\n",
    "    \"sp\": {\n",
    "        \"favela\": \"input/favelas/sao_paulo/LAYER_FAVELAS_2015/DEINFO_FAVELAS_2015.shp\",\n",
    "        \"census_tract\": \"input/census_tracts/sp_setores_censitarios/33SEE250GC_SIR.shp\",\n",
    "    },\n",
    "    \"real_estate\": {\n",
    "        \"sao_paulo_csv\": \"input/real_estate/sao_paulo/data_sao_paulo_concat.csv\",\n",
    "        \"sao_paulo\": \"input/real_estate/sao_paulo/sao_paulo.shp\",\n",
    "        \"brazil_csv\": \"input/real_estate/brazil/data_brazil_concat.csv\",\n",
    "        \"brazil\": \"input/real_estate/brazil/brazil.shp\",\n",
    "        # \"airbnb_rio_csv\": \"input/real_estate/airbnb/airbnb.csv\",\n",
    "        # \"airbnb_rio\": \"input/real_estate/airbnb/airbnb.shp\",\n",
    "    },\n",
    "    \"projections\": {\n",
    "        \"WGS_1984_UTM_Zone_23S_EPSG\": 32723,\n",
    "        \"wgs_84_srid\": 4326\n",
    "    },\n",
    "    \"population\": \"input\\population\\gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_30_sec_brazil.tif\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Cleaning\n",
    "\n",
    "The next few steps were to create geospatial data files (like Shapefiles), remove unneccessary columns and split data into seperate files for following Geoprocessing steps by selection queries. The project data was stored in a Dropbox folder for sharing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import data\n",
    "from geoprocessing import *\n",
    "\n",
    "\n",
    "wd = 'Z:/Dropbox/General_Assembly/Projects/project_5/data'\n",
    "\n",
    "create geospatial files\n",
    "point_table_to_feature_class(\n",
    "    f'{wd}/{data[\"real_estate\"][\"airbnb_rio_csv\"]}',\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    data[\"projections\"][\"wgs_84_srid\"],\n",
    "    f\"{wd}/input/real_estate/airbnb\",\n",
    "    \"airbnb.shp\",\n",
    ")\n",
    "\n",
    "delete_fields(\n",
    "    f'{wd}/{data[\"real_estate\"][\"airbnb_rio\"]}',\n",
    "    [\n",
    "        \"name\",\n",
    "        \"host_id\",\n",
    "        \"host_name\",\n",
    "        \"neighbourh\",\n",
    "        \"neighbou_1\",\n",
    "        \"room_type\",\n",
    "        \"minimum_ni\",\n",
    "        \"number_of_\",\n",
    "        \"last_revie\",\n",
    "        \"reviews_pe\",\n",
    "        \"calculated\",\n",
    "        \"availabili\",\n",
    "        \"id\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "add_field_calculate(\n",
    "    f\"{wd}/{data['real_estate']['airbnb_rio']}\",\n",
    "    'property_t',\n",
    "    'TEXT',\n",
    "    \"'airbnb'\",\n",
    ")\n",
    "\n",
    "\n",
    "for i in ['sao_paulo', 'brazil']:\n",
    "    csv_name = f'{i}_csv'\n",
    "    # create geospatial files\n",
    "    point_table_to_feature_class(\n",
    "        f\"{wd}/{data['real_estate'][csv_name]}\",\n",
    "        \"lon\",\n",
    "        \"lat\",\n",
    "        data[\"projections\"][\"wgs_84_srid\"],\n",
    "        f\"{wd}/input/real_estate/{i}\",\n",
    "        f\"{i}.shp\",\n",
    "    )\n",
    "\n",
    "    df = feature_class_to_dataframe(f\"{wd}/input/real_estate/{i}/{i}.shp\")\n",
    "\n",
    "    for c in list(df['property_t'].unique()):\n",
    "        select_features_by_query(\n",
    "            f\"{wd}/input/real_estate/{i}/{i}.shp\",\n",
    "            f\"{wd}/input/real_estate/{i}/{i}_{c.lower()}.shp\",\n",
    "            f\"\"\" \"property_t\" = '{c}' \"\"\",\n",
    "        )\n",
    "\n",
    "\n",
    "for i in ['airbnb']:\n",
    "    df = feature_class_to_dataframe(f\"{wd}/input/real_estate/{i}/{i}.shp\")\n",
    "\n",
    "    for c in list(df['property_t'].unique()):\n",
    "        select_features_by_query(\n",
    "            f\"{wd}/input/real_estate/{i}/{i}.shp\",\n",
    "            f\"{wd}/input/real_estate/{i}/{i}_{c.lower()}.shp\",\n",
    "            f\"\"\" \"property_t\" = '{c}' \"\"\",\n",
    "        )\n",
    "\n",
    "\n",
    "delete_fields(\n",
    "    f\"{wd}/input/airbnb/brazil/listings.shp\",\n",
    "    [\n",
    "        \"name\",\n",
    "        \"host_id\",\n",
    "        \"host_name\",\n",
    "        \"neighbourh\",\n",
    "        \"neighbou_1\",\n",
    "        \"room_type\",\n",
    "        \"minimum_ni\",\n",
    "        \"number_of_\",\n",
    "        \"last_revie\",\n",
    "        \"reviews_pe\",\n",
    "        \"calculated\",\n",
    "        \"availabili\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
